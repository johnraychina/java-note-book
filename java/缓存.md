# 缓存

为什么用缓存？答：降低RT，提高吞吐量。

## 为什么缓存能起到提高吞吐率的作用？
- 速度错配：不同存储的速度相差很大，用缓存预存一部分数据，可以加快访问速度，这个过程的本质是空间换时间。
- 数据读多写少：用缓存可以减小数据库的压力。
- 命中率：基于局部性原理，下次请求可能访问的是相同的或者临近的数据。
- [Amdal's Law](https://en.wikipedia.org/wiki/Amdahl%27s_law)  提供了一个富有洞察力的观察：提升一个部分的性能对整体系统有多大影响。
时间占比为p的部分，性能提升k被后，系统速度提升倍数Speedup：S = 1/((1-p) + p/k)

## 缓存实现模式
https://blog.csdn.net/zzh920625/article/details/78027534

- Cache Aside Pattern
- Read/Write Through Pattern: https://img-blog.csdn.net/20170919105915587
- Write Behind(Back) Pattern

### Cache-Aside Pattern

查询：先查缓存，如果没有，则查数据库，然后put缓存

更新：先更新数据库，再删除缓存。
Q 为什么是删除缓存，而不是更新缓存？
A lazy思想，用到时候，按上查询逻辑，自然会加载最新数据

Q 为什么不先删除缓存？
A 如果先删除缓存，更新数据库之前，缓存（大概率）可能被其他线程put旧数据


1.先删除缓存再更新DB
结论：产生脏数据的概率较大（若出现脏数据，则意味着再不更新的情况下，查询得到的数据均为旧的数据）

比如：两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。

2.先更新DB再删除缓存（使用场景多）

结论：产生脏数据的概率较小，但是会出现一致性的问题；若更新操作的时候，同时进行查询操作，若hit，则查询得到的数据是旧的数据。但是不会影响后面的查询。（代价较小）

一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。

该情况出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

### Read/Write Through Pattern
客户端程序实际只管操作缓存，保持清爽，对缓存<-->存储的的同步 全部由服务端自己做了。

### Write Behind(Back) Pattern
更新数据时，客户端程只更新缓存，而服务端程序将缓存批量异步刷到存储中。
一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗？

这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。

但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。

另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。


# 缓存一致性问题
一致性问题，前面  【缓存实现模式】 已有介绍。


# 缓存未命中的问题

## 缓存雪崩
https://juejin.im/post/6844904057325223944

https://juejin.im/post/6844903813904596999  

某个时刻发生大规模缓存失效（比如失效时间相同，或者缓存挂掉），请求都打到数据库的现象，称为【缓存雪崩】

## 缓存击穿
大量请求访问同一个key（热点数据），此时这个key正好失效，导致请求全部打到数据库，我们吧这样的现象称为【缓存击穿】。

<b> 解决思路 </b>
查数据库时加锁,2种加锁都行：加分布式锁、按机器加锁（允许每台服务器查一次数据库）
加锁前成功后再次check缓存（否则第二个线程得到了锁还是会查数据库，有没有double-check lock的味道?）

由于数据库自带buffer，所以请求相同数据对存储的压力不大，只是比较消耗网络和连接池，最好在服务器端就能处理掉这些请求。

## 热点数据集中失效

<b> 解决思路 </b>
- 设置不同的失效时间
- 采用缓存击穿的解决办法，加锁
- 永不失效，就是采用定时任务对快要失效的缓存进行更新缓存和失效时间

## 缓存命中率低，轮换快
缓存太小，不同key的请求很多，导致轮换太快，频繁IO
这种危害程度比较大，会导大量数据库IO，致数据库buffer命中率低下

<b> 解决思路 </b>
- 1、加大缓存
- 2、缓存分片


## 缓存穿透
请求不存在的数据，也就是说缓存查不到这些数据，请求打到数据库了，这种查询不存在数据的现象称为【缓存穿透】。

<b> 解决思路</b>
- 1、缓存空值
小心！一定要设置失效时间 或者 插入数据库时invalidate/evict空值，否则后续真的有值了，却因为缓存了空值，导致返回空。
- 2、BloomFilter 
https://llimllib.github.io/bloomfilter-tutorial/

# 其他参考实现

## CPU缓存 MESI协议
维基百科，科学上网：https://zh.wikipedia.org/wiki/MESI%E5%8D%8F%E8%AE%AE

## 操作系统-文件缓存实现

## 数据库缓存MySQL Buffer Pool




## Spring Cache 设计
参考：https://docs.spring.io/spring/docs/current/spring-framework-reference/integration.html#cache

- @Cacheable: Triggers cache population. 
- @CacheEvict: Triggers cache eviction.
- @CachePut: Updates the cache without interfering with the method execution.
- @Caching: Regroups multiple cache operations to be applied on a method.
- @CacheConfig: Shares some common cache-related settings at class-level.


Cache
AbstractValueAdaptingCache
CacheManager
CacheAspectSupport

## 本地缓存
ConcurrentHashMap自己实现过期策略

EhCache

Guava Cache

Caffeine

MapDB



## 远程缓存
Redis

Memcache
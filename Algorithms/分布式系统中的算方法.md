

Leslie Lamport

GFS, MapReduce, Chubby, Google spanner



冗余系统健壮性：分布式存储，冗余N个节点，假设节点失败概率是p且相互独立，允许少于一半的节点失败(<=F)，那么系统健壮性>= 1- p^F
一致性问题：N个冗余节点，添加一条记录，如何保证数据一致性？


# 0. leader选举，使用leader进行同步

# 1、paxos对等共识算法: a peer-to-peer concensus algorithm 
问题模型：N个节点，通过网络通讯，对某一个提案达成共识concensus
总体思路：
- 少数服从多数，N=2F+1个节点，允许F个节点失败。
- 达成的共识最终会被所有节点知道
- 节点同意提案不会局限于自己提出的提案
- 通信消息可以丢失，但是不允许篡改.

问题：怎么识别提案？
需要一个唯一序列号，所以一个提案表示成Proposal(seqNum, value)。

问题：怎么样确保中间通信断掉后重启可恢复？
持久化存储log

问题：怎么样通信达成共识？
本质上做二阶段提交


我们把达成共识的一轮通信和决策过程称为一次paxos process.

我们定义分为3个角色：Proposer发送提案, Acceptor对收到的提案进行决策，Learner收到共识提案.

0 客户请求提交给某个Proposer
1. Proposer生成一个唯一的提案Proposal，将Prepare(proposalId)消息广播给Acceptor 
2. Acceptor执行逻辑
  2.1 如果 proposalId 小于Acceptor.maxId, 忽略
  2.2 否则记录下来maxId=proposalId, 然后返回promise(proposalId)给Proposer
3. Proposer如果在一定时间周期内收到了多数节点的promise，他将AcceptRequest(proposalId, value)消息广播Acceptor
4. Acceptor执行逻辑
  4.1 如果 proposalId 小于Acceptor.maxId, 忽略
  4.2 否则 判断之前有接受其他提案？
    如果有接受其他提案，则返回Promise(otherProposalId, otherValue)
    如果没接受，accept接受此提案, 返回Accept(proposalId, value)给Proposer，并广播给Learners
    

  如果多数节点接受此提案，说明系统达到了共识状态。
5. Proposer或Learner收到了多数节点的Accept消息，则他知道系统达到了了共识状态。

DFFdffSDfd22342342343434212345768909akdf;lkjdfhgksdfjkshtisnthisdf
sthisldfkgodfmnnnnnznx,mvbn,zxmvb
1239kdfjjtksh;][[[][][][\\\\|||\]]]


Client                    Proposer                    Acceptor                Learner
  |
  x-------------------------|
  |                         |
  |                         |
  |
  |
  |
  |
  |
  |
  |
  |
  |
  |
  |




# 2、限流算法 Rate Limiting
https://cloud.google.com/solutions/rate-limiting-strategies-techniques
why: 
- 防止Dos攻击，系统雪崩，至少保证部分用户可用、部分请求正常响应
- 管理配额和费用：比如付费限速、流量


## 令牌桶 Token Bucket
permits表示令牌数（也叫许可），+1表示生成令牌，-1表示消费令牌， 对突发流量友好

Guava的RateLimiter使用:
```java
        RateLimiter rateLimiter = RateLimiter.create(2); //创建限流器``        
        rateLimiter.acquire(1); //获取令牌
        doSomeLimitedOperation(); //执行被限流的业务逻辑
```

guava的RateLimiter是令牌桶的一个实现
基本思想是：每次获取令牌时，看下令牌够不够，如果不够再看需要多久，然后sleep一下。
如何按固定速率生成令牌呢？
一个思路是，新起一个线程来做
而guava用另外一个思路：基于事件（请求）来触发令牌生成和消费逻辑。

**关键实现一**

nextFreeTicketMicros 可自由获取令牌时间点 

作用1：每次请求令牌都会可能将这个值往后推（令牌等待时间），越大的请求往后推得越多，每次请求会得一个时间点，再减去当前时间计算出需要等待令牌的时间
这个设计相当于给下个请求一个提示，可以避免线程一哄而上请求令牌导致过多争抢。

作用2：辅助计算生成新令牌，新令牌数 = (当前时间-nextFreeTicketMicros) / 每个令牌需要的间隔时间

**关键实现二**

Q：guava的RateLimiter是怎么应对并发问题的？

A： 给对象加锁 synchronized(mutex())

**关键实现三**
模板方法实现多种策略，瞬间飙升burst或者warmup慢启动
```java
  // 有足够的令牌时，需要等待时间
  abstract long storedPermitsToWaitTime(double storedPermits, double permitsToTake);

  // 新令牌生成的间隔时间
  abstract double coolDownIntervalMicros();
```

### 核心代码

```java
  public double acquire(int permits) {
    long microsToWait = reserve(permits); //为了保证限流，预约令牌 计算所需等待时间
    stopwatch.sleepMicrosUninterruptibly(microsToWait);//sleep等一等
    return 1.0 * microsToWait / SECONDS.toMicros(1L);
  }

  final long reserve(int permits) { //预约令牌
    checkPermits(permits);
    synchronized (mutex()) { //给对象加锁，确保多线程的可见性和原子性
      return reserveAndGetWaitLength(permits, stopwatch.readMicros()); //获取锁，预约令牌
    }
  }

  final long reserveAndGetWaitLength(int permits, long nowMicros) {
    long momentAvailable = reserveEarliestAvailable(permits, nowMicros); //预留令牌并算出可用时间点
    return max(momentAvailable - nowMicros, 0);
  }


  final long reserveEarliestAvailable(int requiredPermits, long nowMicros) {
    resync(nowMicros); //按当前时间同步更新令牌
    long returnValue = nextFreeTicketMicros;  //下次自由获取令牌时间 先作为返回值，然后再计算下一个时间
    double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //需要的令牌，现存的令牌，取min = 可以花掉的令牌
    double freshPermits = requiredPermits - storedPermitsToSpend; //需要的令牌 - 可以花掉的令牌 = 还需要再请求令牌数

    //算一下要等多久：可以花掉的令牌要等多久（按策略控制，对于smooth burst这种不需预热允许瞬间飙升的等待时间是0) + 还需要再请求令牌数*两个请求间隔时间
    //如果请求令牌没超过现存令牌，且使用smooth burst策略，这个值就是0
    long waitMicros =
        storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) 
            + (long) (freshPermits * stableIntervalMicros); 

    //下次自由获取令牌时间 += 等待时间
    this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros);
    //扣减现存令牌
    this.storedPermits -= storedPermitsToSpend;
    return returnValue;
  }

  void resync(long nowMicros) {
    // 如果当前时间超过了自由获取令牌时间，说明可以生成新的令牌了
    // if nextFreeTicket is in the past, resync to now
    if (nowMicros > nextFreeTicketMicros) {
      //生成新的令牌 = (当前时间 - 自有获取令牌时间)/允许的请求间隔时间
      double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros();
      //确保现存令牌上限不超过最大限额
      storedPermits = min(maxPermits, storedPermits + newPermits);
      //自由获取令牌时间 重置为当前时间
      nextFreeTicketMicros = nowMicros;
    }
  }
```




## 漏桶 Leaky Bucket
实现：FIFO 有界队列 + 时间戳，来一个请求尝试leak
优点：削峰填谷效果好，对流量整形
缺点：对突发流量不友好


## 固定（请求数）窗口 Fixed Window
实现方式：请求放入有界队列，队列满了则拒绝处理。
优点：简单可靠，适用于有限资源，一个时刻只能处理固定请求数，但对速率没有要求的场景，支持burst突发流量。
缺点：不平滑，临界问题，最多2倍请求量(burst at end of first window + burst at start of second window)。

## 滑动窗口 Slide Window
和固定窗口类似，但每次处理完一个请求，就向后滑动，来平滑了请求突增问题，redis的键值过期就采用了这种技术。
优点：这种方法能够贴合系统处理能力，滑动速度是和系统处理能力耦合的。
Systems such as Redis facilitate this technique with expiring keys.

# 3、负载均衡 Load Balancing
分布式系统通常是多机服务，所以需要一个合适的策略来选择将请求分发给哪个服务器。
硬件负载均衡(F5) VS 软件负载均衡(LVS, HA-Proxy, Nginx)

（加权）随机
（加权）轮询
一致性哈希
最小活跃数 Least Active Count
最少连接数 Least Connection Count


# 4、缓存淘汰算法





## 02 | MapReduce后谁主沉浮：怎样设计下一代数据处理技术？

- 我们需要一种技术抽象让多步骤数据处理变得易于维护：DAG

- 我们不想要复杂的配置，需要能自动进行性能优化

- 我们要能把数据处理的描述语言，与背后的运行引擎解耦合开来

- 我们要统一批处理和流处理的编程模型

批处理一套api和pipline
流处理一套api和pipline
需要维护两套，一旦业务需求变化，就得大改甚至重做 
===> 解法：流批一体化，即使业务需求变化，开发者也不用频繁修改代码

- 我们要在架构层面提供异常处理和数据监控的能力

大规模数据处理工程实践难点：异常监控、诊断、处理


## 03 | 大规模数据处理初体验：怎样实现大型电商热销榜

例子 --> 单机方案 --> 应对大数据量: 集群多步骤流水线 --> 应对场景变化：框架

## 04 | 分布式系统（上）：学会用服务等级协议SLA来评估你的系统

1. 可用性（Availabilty）

2. 准确性（Accuracy）：错误率（Error Rate）= 导致系统内部错误的有效请求数/期间的有效请求总数
准确性指的是我们所设计的系统服务中，是否允许某些数据是不准确的或者是丢失了的。
如果允许这样的情况发生，用户可以接受的概率（百分比）是多少？

Google Cloud Platform 的 SLA 中，有着这样的准确性定义：每个月系统的错误率超过 5% 的时间要少于 0.1%，以每分钟为单位来计算。

而亚马逊 AWS 云计算平台有着稍微不一样的准确性定义：以每 5 分钟为单位，错误率不会超过 0.1%。你看，我们可以用错误率来定义准确性，但具体该如何评估系统的准确性呢？一般来说，我们可以采用性能测试（Performance Test）或者是查看系统日志（Log）两种方法来评估。


3. 系统容量(Capacity)：QPS
想要得到系统能承受的最大 QPS，更多的是性能测试和日志分析相结合的手段。

4. 延迟(Latency): P99 1秒

在定义延迟的 SLA 时，我们常常看到系统的 SLA 会有 p95 或者是 p99 这样的延迟声明。这里的 p 指的是 percentile，也就是百分位的意思。如果说一个系统的 p95 延迟是 1 秒的话，那就表示在 100 个请求里面有 95 个请求的响应时间会少于 1 秒，而剩下的 5 个请求响应时间会大于 1 秒。

## 05 | 分布式系统（下）：架构师不得不知的三大指标
CAP 理论：一致性、可用性、分区

可扩展性(Scalability)
一致性(Data Consistency)
持久性(Data Durability)


## 06 | 如何区分批处理还是流处理？
有界，无界

## 07 | Workflow设计模式：让你在大规模数据世界中君临天下
复制模式、过滤模式、分离模式和合并模式。

## 08 | 发布/订阅模式：流处理架构中的瑞士军刀

## 10 | Lambda架构：Twitter亿级实时数据分析架构背后的倚天剑
Lambda 架构总共由三层系统组成：
批处理层（Batch Layer），
速度处理层（Speed Layer），
以及用于响应查询的服务层（Serving Layer）。

例子：找车位软件

## 11 | Kappa架构：利用Kafka锻造的屠龙刀
Lambda架构的问题：需要维护两套系统，要保证两套系统计算逻辑一致。

Jay Kreps问了2个问题，于是有了Kappa架构:
我们能不能改进 Lambda 架构中速度层的系统性能，使得它也可以处理好数据的完整性和准确性问题呢？
我们能不能改进 Lambda 架构中的速度层，使它既能够进行实时数据处理，同时也有能力在业务逻辑更新的情况下重新处理以前处理过的历史数据呢？


Kappa架构缺陷：
因为 Kappa 架构只保留了速度层而缺少批处理层，在速度层上处理大规模数据可能会有数据更新出错的情况发生，
这就需要我们花费更多的时间在处理这些错误异常上面。

小结：
如果你所面对的业务逻辑是设计一种稳健的机器学习模型来预测即将发生的事情，那么你应该优先考虑使用 Lambda 架构，因为它拥有批处理层和速度层来确保更少的错误。

如果你所面对的业务逻辑是希望实时性比较高，而且客户端又是根据运行时发生的实时事件来做出回应的，那么你就应该优先考虑使用 Kappa 架构。

## 12 | 我们为什么需要Spark？

Hadoop的问题：
1. MapReduce抽象层次低，大量的底层逻辑都需要开发者手工完成。
2. 只提供Map和Reduce，操作对开发者非常不友好，维护一个多任务协调的状态机成本很高
3. 在Hadoop中，每个Job的计算结果都存储到HDFS文件系统中，大量的IO导致系统延迟很高。
由于这个原因，MapReduce对迭代算法的处理性能都很差，而且很消耗资源：每次迭代都要进行HDFS读写。
4. 只支持批处理数据，欠缺对数据流处理的支持。

Spark特性
1. RDD编程模型提供了简单的api.
2. 快：不用每次都读写HDFS，大部分时候都是内存计算.
3. 从狭义上来看，Spark 只是 MapReduce 的替代方案，大部分应用场景中，它还要依赖于 HDFS 和 HBase 来存储数据，依赖于 YARN/K8s/standalone 来管理集群和资源。

任务模型对比：
在任务（task）级别上，Spark 的并行机制是多线程模型，而 MapReduce 是多进程模型。
MapReduce多进程模型便于细粒度控制每个任务占用的资源，但会消耗较多的启动时间。
Spark多线程模型，使得多个任务运行在同一个JVM进程中，可以带来更快的启动速度、更高的SPU利用率，以及更好的内存共享。


## 13 | 弹性分布式数据集：Spark大厦的地基（上）
RDD 弹性分布式数据集：抽象模型 + api

分区、不可变、并行操作








